#include <iostream>
#include <stdlib.h>
#include <filesystem>
#include <fstream>
#include <string>
#include <queue>
#include <random>
#include <thread>
#include <condition_variable>
#include <armadillo>
#include "rapidjson/document.h"
#include "rapidjson/filereadstream.h"
#include "InputBatch.h"
/*
	TROUBLESHOOTING:

	-If can't open a library in application lib, run sudo ldconfig /home/rthugh02/Documents/Masters_Project/NN_Project/lib
	to refresh library cache

	TODO AND NOTES:

	Layers/steps to build:
	
	- change dense net matrices to be initialized after convolution to have correct Input settings
	- Implement LSTM layer
	- add gamma and beta to batch normalization 
	- Add bias to dense net

*/

//*****************************//
//*********FUNCTIONS***********//
//*****************************//

void convolution(arma::cube *, arma::mat *);
void LSTM(arma::cube *);
void max_pooling(arma::cube *, int);
void train(std::vector<arma::mat *>, arma::mat *);
void convert_data(std::vector<std::string>);
arma::rowvec genre_to_output(const char *);
const char * output_to_genre(arma::rowvec);
void feed_forward(InputBatch *, std::vector<arma::mat *>, arma::mat *);
void activation_function(arma::mat *, const char *);
void batch_normalization(arma::cube *);

//*****************************//
//*********CONSTANTS***********//
//*****************************//

//Batch size of calculations that will be done for back propogation
const int INPUT_BATCH_SIZE = 50;
//Input Neurons
const int INPUT_COUNT = 1294; //This will be determined after maxpooling is finished
const int DATA_ROWS = 128;
const int DATA_ROW_LENGTH = 1294;
const int KERNEL_WIDTH = 3;
//Number of neurons in first hidden layer
const int LAYER_ONE_INPUT = 64;
//Number of neurons in second hidden layer
const int LAYER_TWO_INPUT = 32;
//Output Neurons, there are 8 genre classifications
const int OUTPUT_COUNT = 8;
//number of threads to use for parsing files
const int THREAD_COUNT = 11;

//*******************************//
//*********SHARED VARS***********//
//*******************************//

//keep running count of threads that are still parsing files so train thread knows when to stop
int unfinished_threads = THREAD_COUNT;
//mutex for thread safe enqueueing/dequeueing
std::mutex queue_mutex;
//mutex for thread safe decrementing of unfinished_threads
std::mutex finish_mutex;
//condition variable used by train thread to make the assigned thread block when queue is empty
std::condition_variable cond;
//queue shared by threads
std::queue<InputBatch *> input_queue;

int main() 
{
	//Random seed for initializing weights
	std::random_device rd;
	
	//Uniform distribution of real numbers
	std::normal_distribution<double> distr(0, 1);

	//dense layer weights
	arma::mat * weights1 = new arma::mat(INPUT_COUNT, LAYER_ONE_INPUT);
	arma::mat * weights2 = new arma::mat(LAYER_ONE_INPUT, LAYER_TWO_INPUT);
	arma::mat * weights3 = new arma::mat(LAYER_TWO_INPUT, OUTPUT_COUNT);

	//kernel weights for convolution layer
	arma::mat * kernel = new arma::mat(DATA_ROWS, KERNEL_WIDTH);
	
	//mersenne twister engine for generating random values
	std::mt19937 engine(rd());

	//filling weight matrices with random values generated by mersenne engine by cell
	weights1->imbue( [&]() {return distr(engine) * 2 / (INPUT_COUNT); } );
	engine.seed(rd());
	weights2->imbue( [&]() {return distr(engine) * 2 / (LAYER_ONE_INPUT); } );
	engine.seed(rd());
	weights3->imbue( [&]() {return distr(engine) * 2 / (LAYER_TWO_INPUT); } );
	engine.seed(rd());
	kernel->imbue( [&]() {return distr(engine) * 2 / (DATA_ROWS); } );

	//threads that will parse song_data directory and generate input data for NN
	std::vector<std::thread> directory_threads;

	std::vector<arma::mat *> dense_weights;
	dense_weights.push_back(weights1);
	dense_weights.push_back(weights2);
	dense_weights.push_back(weights3);
	//thread dedicated to feed-forward/back-propogation of NN
	std::thread train_thread(train, dense_weights, kernel);
	
	//Iterating through all song data that will be used as input
	int song_count = 0;
	std::vector<std::string> thread_tasks[THREAD_COUNT];
	//assigning each file to a thread
	for(const auto & file : std::filesystem::directory_iterator("song_data/"))
		thread_tasks[song_count++ % THREAD_COUNT].push_back(file.path().string());
	
	//launching threads for converting song_data files
	for(auto & task : thread_tasks)
		directory_threads.emplace_back(convert_data, task);

	//joining threads
	for(auto & thread : directory_threads)
		thread.join();
	train_thread.join();
}

//Function for retreiving batches of song data from queue for feed-forward/backpropogation
void train(std::vector<arma::mat *> dense_weights, arma::mat * kernel)
{
	//while there are directory threads still doing work
	int batch_count = 0;
	while(unfinished_threads > 0) 
	{
		//if queue is empty block this thread so as not to waste CPU time polling 
		std::unique_lock<std::mutex> lock(queue_mutex);
		while (input_queue.empty())
			cond.wait(lock);
		
		InputBatch * next = input_queue.front();
		input_queue.pop();

		feed_forward(next, dense_weights, kernel);
		next->free();
		std::cout << "consuming item " << ++batch_count << " from queue" << std::endl;
	}
}

//TODO: add bias to this process
void feed_forward(InputBatch * input, std::vector<arma::mat *> dense_weights, arma::mat * kernel)
{
	//Process: convolution -> LSTM -> dense -> output
	convolution(input->data, kernel);


	//activation_function(input->data, "softmax");
}

void convolution(arma::cube * data, arma::mat * kernel)
{
	// process: 1D convolution -> ReLu -> Batch normalization -> maxpooling
	
	//1D convolution and ReLu
	for(arma::uword slice = 0; slice < data->n_slices; slice++)
	{
		arma::mat convoluted_vectors(data->n_rows, data->n_cols);

		//calculate convoluted vectors centered around each column of the matrix
		for(arma::uword j = 0; j < data->n_cols; j++)
		{
			arma::mat sub_mat;
			
			//apply padding vectors on the left-most part of the X-axis
			if(j < ((KERNEL_WIDTH - 1) / 2))
			{
				int padding, index = 0;
				for(padding = j; padding < ((KERNEL_WIDTH - 1) / 2); padding++)
					sub_mat.insert_cols(index++,arma::colvec(data->n_rows, arma::fill::zeros));
				for(int remaining = 0; padding < KERNEL_WIDTH; padding++)
					sub_mat.insert_cols(index++, data->slice(slice).col(remaining++));
			}
			//apply padding vectors to right-most part of the X-axis
			else if(j >= data->n_cols - ((KERNEL_WIDTH - 1) / 2))
			{
				int index = 0;
				for(arma::uword adding = (j - ((KERNEL_WIDTH - 1) / 2)); adding < data->n_cols; adding++)
					sub_mat.insert_cols(index++, data->slice(slice).col(adding));
				for(; index < KERNEL_WIDTH; index++)
					sub_mat.insert_cols(index,arma::colvec(data->n_rows, arma::fill::zeros));
			}
			//no padding needed
			else
			{
				sub_mat = data->slice(slice).cols(j - ((KERNEL_WIDTH - 1) / 2), j + ((KERNEL_WIDTH - 1) / 2) );
			}

			convoluted_vectors.col(j) = arma::sum( (sub_mat % *(kernel)) , 1);
		}
		data->slice(slice) = convoluted_vectors;
		activation_function(&data->slice(slice), "relu");
	}
	batch_normalization(data);
	max_pooling(data, 2);
}

void max_pooling(arma::cube * data, int step)
{
	arma::mat temp[INPUT_BATCH_SIZE];

	int new_column_size = 0;
	//for each song in the batch
	for(arma::uword slice = 0; slice < data->n_slices; slice++)
	{
		arma::mat pooled_song;
		int index = 0;
		//pooling based on step size for no overlap
		for(arma::uword j = 0; j < data->n_cols; j+= step)
		{
			pooled_song.insert_cols(index++ ,
			(arma::colvec) arma::max(data->slice(slice).submat(0, j, DATA_ROWS - 1, j + step - 1), 1));
		}
		//storing new column size and each pooled entry
		new_column_size = pooled_song.n_cols;
		temp[slice] = pooled_song;
	}
	//setting size of data post max-pooling
	data->set_size(DATA_ROWS, new_column_size, INPUT_BATCH_SIZE);
	
	//re-assigning data with calculated max-pools
	for(arma::uword i = 0; i < data->n_slices; i++)
		data->slice(i) = temp[i];
}

/*
Notes on LSTM:

LSTM layers are not densely connected LSTM cells, each cell operates on itself in a loop
an LSTM layer accepts all the inputs from the layer leading into it
View the graph in this link for conceptual view: https://www.quora.com/In-LSTM-how-do-you-figure-out-what-size-the-weights-are-supposed-to-be

Plan:
- Input Batch data cube structure is passed to LSTM
- each top to bottom slice of the cube, representing the song batches divided by their mel data, 
  will be passed to an LSTM unit
- these slices in their individual LSTM units will be divided into T submatrices 
  and passed to the corresponding connected cells within the LSTM unit
- The outputs will then be calculated and concatenated and replace its corresponding slice in the batch

*/
void LSTM(arma::cube * data)
{

}

//TODO: Make sure to review softmax code for correctness
void activation_function(arma::mat * input, const char * function)
{
	if(strcmp("relu", function) == 0)
		input->transform([] (double val) { return std::max(0.0, val); } );
	else if(strcmp("leakyrelu", function) == 0)
		input->transform([] (double val) { return (val < 0) ? 0.01*val : val; } );
	else if(strcmp("sigmoid", function) == 0)
		input->transform([] (double val) { return (1 / (1 + exp(-val))); } );
	else if(strcmp("tanh", function) == 0)
		input->transform([] (double val) { return (exp(val) - exp(-val)) / (exp(val) + exp(-val)) ; } );
	else if(strcmp("softmax", function) == 0)
	{

		//getting max of each row into column vector
		arma::colvec row_max = arma::max(*input, 1);

		//expanding row max to be a matrix to perform max subtraction trick
		arma::mat max_subtractor(input->n_rows,0);
		for(arma::uword i = 0; i < input->n_cols; i++)
			max_subtractor.insert_cols(i, row_max);
		
		//subtracting max value of each row from each value in the row to prevent extremely large exponentiation
		*(input) -= max_subtractor;

		//input->print("submax:");

		//exponentiating data to start softmax 
		input->transform([] (double val) { return exp(val); } );

		//input->print("exponentiate:");
		//summation of each exponentiated row
		arma::colvec row_summation = arma::sum(*input, 1);
		
		//creating matrix to perform Hadamard product to get softmax probabilities
		arma::mat sum_multiplier (input->n_rows, 0);
		for(arma::uword i = 0; i < input->n_cols; i++)
			sum_multiplier.insert_cols(i, row_summation);
		

		*(input) %= (1 / sum_multiplier);

		//input->print("output:");
		
	}
}

//TODO: Add in gamma and beta scale/shift values that can be trained
//Normalization such that norm(val) = (val - mean) / sqrt(variance + er)
void batch_normalization(arma::cube * batch) 
{
	arma::mat feature_means = arma::mean(*batch, 2);
	arma::mat feature_variances = arma::sum(
		(batch->each_slice() - feature_means).transform([] (double val) { return val*val; } ), 2) / batch->n_rows; 
	
	//denominator of normalization formula
	feature_variances.transform([] (double val) { return sqrt(val + 0.0001); } );
	//subtracting means for numerator
	batch->each_slice() -= feature_means;
	//normalized values
	batch->each_slice() %= (1 / (feature_variances));
}

/*files assigned to thread are parsed and used to create matrix rows that are inserted into
matrices of row size INPUT_BATCH_SIZE. These matrices are then enqueued and consumed 
by the training thread.
*/
void convert_data(std::vector<std::string> files)
{
	//JSON parser
	rapidjson::Document document;
	int row_counter = 0;

	std::vector<arma::mat> song_buffer;
	std::vector<arma::rowvec> genre_buffer; 

	//closure for creating batch of song data and enqueueing 
	auto build_batch = [&]() {
			row_counter = 0;

			//song batch data
			arma::cube * input_batch = new arma::cube(DATA_ROWS, DATA_ROW_LENGTH, INPUT_BATCH_SIZE);
			arma::mat * correct_output = new arma::mat(0, OUTPUT_COUNT);
			for(auto it = song_buffer.begin(); it != song_buffer.end(); it++)
			{
				input_batch->slice(row_counter) = *it;
				correct_output->insert_rows(row_counter, genre_buffer[row_counter]);
				row_counter++;
			}
			//thread safe enqueuing and notify training thread there is work to do
			queue_mutex.lock();
			input_queue.push(new InputBatch(input_batch, correct_output));
			cond.notify_one();
			queue_mutex.unlock();

			song_buffer.clear();
			genre_buffer.clear();
			row_counter = 0;
	};
	for(const auto & file : files)
	{
		if(row_counter < INPUT_BATCH_SIZE)
		{
			//Reading song data into string
			std::ifstream f(file);
			std::string content( (std::istreambuf_iterator<char>(f) ),
        	            (std::istreambuf_iterator<char>()));

			//parsing json data 
			document.Parse(content.c_str());
			auto raw_data = document["data"].GetArray();
			auto genre = document["genre"].GetString();

			arma::mat spectogram_data(0, DATA_ROW_LENGTH);
			for(rapidjson::SizeType i = 0; i < raw_data.Size(); i++) 
    		{
				std::vector<double> temp;
				int inner_row_count = 0;
        		rapidjson::Value& row = raw_data[i];
        		for(rapidjson::SizeType j = 0; j < row.Size(); j++)
				{
					temp.push_back(row[j].GetDouble());
					inner_row_count++;
				}
				//adding missing time data to end if not long enough
				while(inner_row_count < DATA_ROW_LENGTH)
				{
					temp.push_back(0);
					inner_row_count++;
				}
				spectogram_data.insert_rows((int)i, arma::rowvec(temp));				
    		}

			song_buffer.push_back(spectogram_data);
			genre_buffer.push_back(genre_to_output(genre));
			row_counter++;
		}
		else
			build_batch();	
	}
	if(row_counter > 0)
		build_batch();
	
	finish_mutex.lock();
	unfinished_threads--;
	finish_mutex.unlock();
	std::cout << "thread finished.." << std::endl;
}

/*
	mapping:
	
	Hip-Hop			1 0 0 0 0 0 0 0
	Pop				0 1 0 0 0 0 0 0
	Electronic		0 0 1 0 0 0 0 0
	Instrumental	0 0 0 1 0 0 0 0
	International	0 0 0 0 1 0 0 0
	Folk			0 0 0 0 0 1 0 0
	Experimental	0 0 0 0 0 0 1 0
	Rock			0 0 0 0 0 0 0 1
*/

arma::rowvec genre_to_output(const char * genre)
{
	if(strcmp("Hip-Hop", genre) == 0)
		return arma::rowvec("1 0 0 0 0 0 0 0");
	else if(strcmp("Pop", genre) == 0)
		return arma::rowvec("0 1 0 0 0 0 0 0");
	else if(strcmp("Electronic", genre) == 0)
		return arma::rowvec("0 0 1 0 0 0 0 0");
	else if(strcmp("Instrumental", genre) == 0)
		return arma::rowvec("0 0 0 1 0 0 0 0");
	else if(strcmp("International", genre) == 0)
		return arma::rowvec("0 0 0 0 1 0 0 0");
	else if(strcmp("Folk", genre) == 0)
		return arma::rowvec("0 0 0 0 0 1 0 0");
	else if(strcmp("Experimental", genre) == 0)
		return arma::rowvec("0 0 0 0 0 0 1 0");
	else //Rock
		return arma::rowvec("0 0 0 0 0 0 0 1");
}

const char * output_to_genre(arma::rowvec output)
{
	if(output[0] == 1)
		return "Hip-Hop";
	else if(output[1] == 1)
		return "Pop";
	else if(output[2] == 1)
		return "Electronic";	
	else if(output[3] == 1)
		return "Instrumental";	
	else if(output[4] == 1)
		return "International";	
	else if(output[5] == 1)
		return "Folk";	
	else if(output[6] == 1)
		return "Experimental";	
	else
		return "Rock";		
}
